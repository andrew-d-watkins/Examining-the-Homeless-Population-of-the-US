{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the Homeless Population of the United States\n",
    "By Andrew Watkins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Wrangling from previous section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Name the files to use\n",
    "file_hic_state = 'data/2007-2017-HIC-Counts-by-State.xlsx'\n",
    "file_pit_state = 'data/2007-2017-PIT-Counts-by-State.xlsx'\n",
    "\n",
    "# Load spreadsheet\n",
    "hic_state = pd.ExcelFile(file_hic_state)\n",
    "pit_state = pd.ExcelFile(file_pit_state)\n",
    "\n",
    "#HIC\n",
    "df_hic = pd.DataFrame()\n",
    "\n",
    "#concat the rest of the sheets to the original df\n",
    "for sheet in range(2007, 2018): \n",
    "    excel_sheet = hic_state.parse(str(sheet), header=1)\n",
    "    excel_sheet['year'] = str(sheet)\n",
    "    excel_sheet.set_index(['year','State'], inplace=True)\n",
    "    df_hic = pd.concat([df_hic, excel_sheet], axis=0, ignore_index=False, sort=True)\n",
    "    \n",
    "#Columns were named differenlty before 2014 so we will use all the named variations and then combine them.\n",
    "columns_to_use = [ \"Total Year-Round Beds (ES)\",\n",
    "                   \"Total Year-Round ES Beds\",\n",
    "                   \"Total Year-Round Beds (TH)\",\n",
    "                   \"Total Year-Round TH Beds\",\n",
    "                   \"Total Year-Round Beds (SH)\",\n",
    "                   \"Total Year-Round SH Beds\",\n",
    "                   \"Total Year-Round Beds (PSH)\",\n",
    "                   \"Total Year-Round PSH Beds\",\n",
    "                   \"Total Year-Round Beds (RRH)\",\n",
    "                   \"Total Year-Round RRH Beds\",\n",
    "                   \"Total Year-Round Beds (DEM)\",\n",
    "                   \"Total Year-Round Beds (OPH)\",\n",
    "]\n",
    "df_hic = df_hic[columns_to_use]\n",
    "df_hic.fillna(0.0, inplace=True)\n",
    "\n",
    "\n",
    "#Here we combine the coumns that contain the same informaiton but were named differently. \n",
    "df_hic['Total Year-Round Beds (ES)'] = df_hic['Total Year-Round Beds (ES)'] + df_hic['Total Year-Round ES Beds']\n",
    "df_hic['Total Year-Round Beds (TH)'] = df_hic['Total Year-Round Beds (TH)'] + df_hic['Total Year-Round TH Beds']\n",
    "df_hic['Total Year-Round Beds (SH)'] = df_hic['Total Year-Round Beds (SH)'] + df_hic['Total Year-Round SH Beds']\n",
    "df_hic['Total Year-Round Beds (PSH)'] = df_hic['Total Year-Round Beds (PSH)'] + df_hic['Total Year-Round PSH Beds']\n",
    "df_hic['Total Year-Round Beds (RRH)'] = df_hic['Total Year-Round Beds (RRH)'] + df_hic['Total Year-Round RRH Beds']\n",
    "\n",
    "#We drop the extra columns we no longer need.\n",
    "cols_to_drop = ['Total Year-Round ES Beds',\n",
    "                'Total Year-Round TH Beds',\n",
    "                'Total Year-Round SH Beds',\n",
    "                'Total Year-Round PSH Beds',\n",
    "                'Total Year-Round RRH Beds']\n",
    "df_hic.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "#PIT\n",
    "#Create a new DF with the rest of the sheets. Which are the homeless population in each state from 2007-2017\n",
    "df_pit = pd.DataFrame()\n",
    "\n",
    "#concat the rest of the sheets to the original df\n",
    "for sheet in range(2007, 2018):\n",
    "    excel_sheet = pit_state.parse(str(sheet))\n",
    "    excel_sheet['year'] = str(sheet)\n",
    "    excel_sheet.set_index(['year','State'], inplace=True)\n",
    "    #rename the columns\n",
    "    cols_to_use = []\n",
    "    for column in excel_sheet.columns:\n",
    "        if column.__contains__(','):\n",
    "            cols_to_use.append(column.split(',')[0])\n",
    "        else:\n",
    "            cols_to_use.append(column)\n",
    "    excel_sheet.columns = cols_to_use\n",
    "    df_pit = pd.concat([df_pit, excel_sheet], axis=0, ignore_index=False, sort=True)\n",
    "    \n",
    "#There are only two with the note. So we just drop them directly. \n",
    "df_pit.drop(level=1, inplace=True, index='Note: The number of CoCs in 2016 was 402. However, MO-604 merged in 2016 and covers territory in both MO and KS, contributing to the PIT count in both states. ')\n",
    "df_pit.drop(level=1, inplace=True, index='Note: The number of CoCs in 2017 was 399. However, MO-604 merged in 2016 and covers territory in both MO and KS, contributing to the PIT count in both states. ')\n",
    "\n",
    "#Grab the 2 columns that we need for now\n",
    "df_pit = df_pit[['Total Homeless', 'Number of CoCs']]\n",
    "df_pit.fillna(0, inplace=True)\n",
    "df_pit.replace(to_replace='.', value='0', inplace=True)\n",
    "df_pit = df_pit.astype(float, copy=False)\n",
    "\n",
    "#Merge both DF (PIT and HIC) and drop some unecessary columns\n",
    "df = pd.concat([df_hic, df_pit], axis=1)\n",
    "df.drop(index=['Total', 'KS*', ' ', 'MP'], level=1, inplace=True)\n",
    "\n",
    "#Create an aggregate column of the total of all the beds.\n",
    "df['Total Beds'] = df_hic['Total Year-Round Beds (ES)'] + df_hic['Total Year-Round Beds (TH)'] + df_hic['Total Year-Round Beds (SH)'] + df_hic['Total Year-Round Beds (PSH)'] + df_hic['Total Year-Round Beds (RRH)'] + df_hic['Total Year-Round Beds (DEM)'] + df_hic['Total Year-Round Beds (OPH)']\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Models\n",
    "-Linear Regression\n",
    "-Logistic Regression (How to divide/classify the total amount of beds?)\n",
    "-Decision Tree\n",
    "-SVM\n",
    "-Naive Bayes\n",
    "-K-Means\n",
    "-Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section:  Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional imports needed for ML\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now need to create a train-test split in our data that we will use on all our models.\n",
    "X=df['Total Homeless'].values.reshape(-1,1)\n",
    "y=df['Total Beds'].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop CA and NY\n",
    "df_min = df.drop(index=['CA', 'NY'], level=1)\n",
    "\n",
    "#We now need to create a train-test split in our data that we will use on all our models.\n",
    "X_min=df_min['Total Homeless'].values.reshape(-1,1)\n",
    "y_min=df_min['Total Beds'].values.reshape(-1,1)\n",
    "\n",
    "X_train_min, X_test_min, y_train_min, y_test_min = train_test_split(X_min, y_min, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve\n",
    "from patsy.builtins import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.8942869051025861\n",
      "Root Mean Squared Error: 5203.300913404745\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     Q('Total Homeless')   R-squared:                       0.820\n",
      "Model:                             OLS   Adj. R-squared:                  0.820\n",
      "Method:                  Least Squares   F-statistic:                     2696.\n",
      "Date:                 Thu, 07 Mar 2019   Prob (F-statistic):          1.37e-222\n",
      "Time:                         14:07:14   Log-Likelihood:                -6211.8\n",
      "No. Observations:                  594   AIC:                         1.243e+04\n",
      "Df Residuals:                      592   BIC:                         1.244e+04\n",
      "Df Model:                            1                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept       -1054.4702    418.539     -2.519      0.012   -1876.472    -232.469\n",
      "Q('Total Beds')     0.9039      0.017     51.927      0.000       0.870       0.938\n",
      "==============================================================================\n",
      "Omnibus:                      396.484   Durbin-Watson:                   1.628\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10340.925\n",
      "Skew:                           2.523   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.808   Cond. No.                     2.91e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.91e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = ols(\"Q('Total Homeless') ~ Q('Total Beds')\", df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "### We now do the same operations with the min df.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.6921948861246401\n",
      "Root Mean Squared Error: 5248.060219215974\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_min, y_train_min)\n",
    "\n",
    "#Predict Output\n",
    "y_pred_min = model.predict(X_test_min)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test_min, y_test_min)))\n",
    "rmse_min = np.sqrt(mean_squared_error(y_test_min, y_pred_min))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     Q('Total Homeless')   R-squared:                       0.665\n",
      "Model:                             OLS   Adj. R-squared:                  0.665\n",
      "Method:                  Least Squares   F-statistic:                     1134.\n",
      "Date:                 Thu, 07 Mar 2019   Prob (F-statistic):          1.18e-137\n",
      "Time:                         14:07:14   Log-Likelihood:                -5678.6\n",
      "No. Observations:                  572   AIC:                         1.136e+04\n",
      "Df Residuals:                      570   BIC:                         1.137e+04\n",
      "Df Model:                            1                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept         341.0452    303.447      1.124      0.262    -254.965     937.055\n",
      "Q('Total Beds')     0.7360      0.022     33.674      0.000       0.693       0.779\n",
      "==============================================================================\n",
      "Omnibus:                      347.143   Durbin-Watson:                   1.605\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5444.021\n",
      "Skew:                           2.368   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.353   Cond. No.                     2.03e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.03e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = ols(\"Q('Total Homeless') ~ Q('Total Beds')\", df_min).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.7557748670573805\n",
      "Root Mean Squared Error: 7908.784208559684\n"
     ]
    }
   ],
   "source": [
    "# Create tree object \n",
    "model = tree.DecisionTreeRegressor() #for regression\n",
    "\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.5423021831180048\n",
      "Root Mean Squared Error: 6399.562940239509\n"
     ]
    }
   ],
   "source": [
    "# Create tree object \n",
    "model = tree.DecisionTreeRegressor()\n",
    "\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X_train_min, y_train_min)\n",
    "\n",
    "#Predict Output\n",
    "y_pred_min = model.predict(X_test_min)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test_min, y_test_min)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test_min, y_pred_min))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.0\n",
      "Root Mean Squared Error: 7908.784208559684\n"
     ]
    }
   ],
   "source": [
    "# Create KNeighbors classifier object model \n",
    "model = KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train.ravel())\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHat threshold or category should I create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.0\n",
      "Root Mean Squared Error: 6399.562940239509\n"
     ]
    }
   ],
   "source": [
    "# Create KNeighbors classifier object model \n",
    "model = KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_min, y_train_min.ravel())\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test_min)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test_min, y_test_min)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test_min, y_pred_min))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.0\n",
      "Root Mean Squared Error: 7949.807465561402\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest object\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train.ravel())\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.008695652173913044\n",
      "Root Mean Squared Error: 6399.562940239509\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest object\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_min, y_train_min.ravel())\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test_min)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(model.score(X_test_min, y_test_min)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test_min, y_pred_min))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use logistic regression to classify the states. However we don't have any columns we can use to classify them. So in order to be able to do some logistic regression we need to create or determine a threshold for our data to be able to determine if the threshold is met and add it as a column. The threshold we are going to add is called 'Able', we are going to classify if the state is able to handle their homeless popualtion based on the bed to homeless ratio. We will plot the distribution of the home to bed ratio and determine what threshold we will use to determine if a state is 'able'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We plot the of the homeless vs the beds in a scatter plot\n",
    "import matplotlib.ticker\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.hist(x=(df['Total Homeless']/df['Total Beds']), bins=30)\n",
    "plt.title('Total Homeless to Beds Ratio')\n",
    "plt.xticks(range(5))\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the distribution we will use anything above .25 as 'able'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total Year-Round Beds (ES)</th>\n",
       "      <th>Total Year-Round Beds (TH)</th>\n",
       "      <th>Total Year-Round Beds (SH)</th>\n",
       "      <th>Total Year-Round Beds (PSH)</th>\n",
       "      <th>Total Year-Round Beds (RRH)</th>\n",
       "      <th>Total Year-Round Beds (DEM)</th>\n",
       "      <th>Total Year-Round Beds (OPH)</th>\n",
       "      <th>Total Homeless</th>\n",
       "      <th>Number of CoCs</th>\n",
       "      <th>Total Beds</th>\n",
       "      <th>Able</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007</th>\n",
       "      <th>AK</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>1766.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5452.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6793.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1483.0</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3836.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>3736.0</td>\n",
       "      <td>5597.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14646.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12352.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>20181.0</td>\n",
       "      <td>30897.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26787.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138986.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>77865.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Year-Round Beds (ES)  Total Year-Round Beds (TH)  \\\n",
       "year State                                                           \n",
       "2007 AK                         1095.0                       663.0   \n",
       "     AL                         1766.0                      2607.0   \n",
       "     AR                         1483.0                      1109.0   \n",
       "     AZ                         3736.0                      5597.0   \n",
       "     CA                        20181.0                     30897.0   \n",
       "\n",
       "            Total Year-Round Beds (SH)  Total Year-Round Beds (PSH)  \\\n",
       "year State                                                            \n",
       "2007 AK                            0.0                        489.0   \n",
       "     AL                            0.0                       2420.0   \n",
       "     AR                            0.0                       1538.0   \n",
       "     AZ                            0.0                       3019.0   \n",
       "     CA                            0.0                      26787.0   \n",
       "\n",
       "            Total Year-Round Beds (RRH)  Total Year-Round Beds (DEM)  \\\n",
       "year State                                                             \n",
       "2007 AK                             0.0                          0.0   \n",
       "     AL                             0.0                          0.0   \n",
       "     AR                             0.0                          0.0   \n",
       "     AZ                             0.0                          0.0   \n",
       "     CA                             0.0                          0.0   \n",
       "\n",
       "            Total Year-Round Beds (OPH)  Total Homeless  Number of CoCs  \\\n",
       "year State                                                                \n",
       "2007 AK                             0.0          1642.0             2.0   \n",
       "     AL                             0.0          5452.0             8.0   \n",
       "     AR                             0.0          3836.0             9.0   \n",
       "     AZ                             0.0         14646.0             3.0   \n",
       "     CA                             0.0        138986.0            42.0   \n",
       "\n",
       "            Total Beds  Able  \n",
       "year State                    \n",
       "2007 AK         2247.0  True  \n",
       "     AL         6793.0  True  \n",
       "     AR         4130.0  True  \n",
       "     AZ        12352.0  True  \n",
       "     CA        77865.0  True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column called 'Able', a boolean value which determines if the ratio of homeless to beds is above .25\n",
    "df['Able'] = df['Total Homeless']/df['Total Beds'] > 0.50\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now need to create a train-test split in our data that we will use on all our models.\n",
    "#X=df[['Total Year-Round Beds (ES)','Total Year-Round Beds (TH)','Total Year-Round Beds (SH)','Total Year-Round Beds (PSH)','Total Year-Round Beds (RRH)','Total Year-Round Beds (DEM)','Total Year-Round Beds (OPH)']]#.values.reshape(-1,1)\n",
    "#y=df['Total Beds']#.values.reshape(-1,1)\n",
    "X=df\n",
    "y=df['Able']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Create logistic regression object\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False False  True  True  True  True  True\n",
      "  True  True False  True  True  True False  True False False False False\n",
      " False  True  True  True  True  True  True  True False  True  True False\n",
      "  True  True False  True False  True  True  True  True False False  True\n",
      "  True  True  True False  True  True  True  True  True  True  True False\n",
      " False False  True  True  True  True  True  True False  True False  True\n",
      " False False False False False False False  True  True  True  True  True\n",
      "  True  True False  True  True False  True  True False  True False  True\n",
      " False  True  True False False  True  True  True False False  True]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8151260504201681\n"
     ]
    }
   ],
   "source": [
    "# Create KNeighbors classifier object model \n",
    "model = KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.31932773109243695\n"
     ]
    }
   ],
   "source": [
    "# Create KNeighbors classifier object model \n",
    "model = KMeans(n_clusters=1)\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Create tree object \n",
    "model = tree.DecisionTreeRegressor() #for regression\n",
    "\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Create SVM classification object \n",
    "model = svm.SVC()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7983193277310925\n"
     ]
    }
   ],
   "source": [
    "# Create SVM classification object \n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred= model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest object\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
